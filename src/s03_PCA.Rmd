---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---


# load packages
```{r}
rm(list = ls())
library(data.table)
#library(reshape)
library(ggplot2)
library(scico)
library(png)
library(abc)
#library(ggpubr)

today = Sys.Date()
```

# load data
```{r}
# simulation parameters
#params = read.table("../config/parameters.tsv", sep = "\t", header = T)
params = read.table("/mnt/scratch/robe1195/Josephs_Lab_Projects/selection-demography-cnn/config/parameters.tsv", sep = "\t", header = T)

# Ne values
#mean_ne = read.table("/mnt/scratch/robe1195/Josephs_Lab_Projects/selection-demography-cnn/workflow/harmonic_mean_ne.txt", sep = " ", header = F, col.names = c("ID", "Ne"))
#params = merge(params, mean_ne, by = "ID")

# merge in fixation times
fix_times = read.table("/mnt/scratch/robe1195/Josephs_Lab_Projects/selection-demography-cnn/workflow/fixation_times.txt", col.names = c("ID", "tf"))

params = merge(params, fix_times, by = "ID")

# merge in sweep ages
sweep_ages = read.table("/mnt/scratch/robe1195/Josephs_Lab_Projects/selection-demography-cnn/workflow/sweep_ages.txt", col.names = c("ID", "ta")) 

params = merge(params, sweep_ages, by = "ID")

# add in selective sweep statistics
sweep_stats_files = list.files(path = "/mnt/scratch/robe1195/Josephs_Lab_Projects/selection-demography-cnn/workflow", pattern = "slim.*.tsv", full.names = T)

sweep_stats = suppressWarnings(lapply(sweep_stats_files, read.table, header = F))

#subset_tables = function(x){
#  if(ncol(x) == 18){
#    x = x[,2:18]
#  }
#  colnames(x) = c("pi", "thetaw", "tajd", "tajd_var", "tajd_incomplete", "num_haplos", "h1", "h2", "h12", "h123", "h2h1", "gkl_var", "gkl_skew", "gkl_kurt", "zns", "omega", "hscan")
#  return(x)
#}

#sweep_stats = lapply(sweep_stats, subset_tables)

#sweep_stats_files = sweep_stats_files[unlist(lapply(sweep_stats, ncol)) == 17]
#sweep_stats = sweep_stats[unlist(lapply(sweep_stats, ncol)) == 17]

sweep_stats = do.call("rbind", sweep_stats)

colnames(sweep_stats) = c("S", "pi", "thetaw", "tajd", "tajd_var", "tajd_incomplete", "num_haplos", "h1", "h2", "h12", "h123", "h2h1", "gkl_var", "gkl_skew", "gkl_kurt", "zns", "omega", "hscan")

sweep_stats$ID = as.numeric(gsub(".tsv", "", gsub(".*slim_", "",sweep_stats_files)))

params = merge(params, sweep_stats, by = "ID")

# get simulation outputs
mypics = list.files("/mnt/scratch/robe1195/Josephs_Lab_Projects/selection-demography-cnn/workflow/data/images", full.names = T)

# get sim ids
picids = as.integer(gsub(".png", "", gsub("/mnt/scratch/robe1195/Josephs_Lab_Projects/selection-demography-cnn/workflow/data/images/slim_", "", mypics)))

# only keep simulations that have images
params = params[(params$ID %in% picids),]
```

# Exploratory data analysis
```{r}
# plot fixation times for different types of sweeps
# params$sweepType = NA
# params$sweepType[( (params$f0 == 0) & (params$f1 == 1) )] = "hard"
# params$sweepType[( (params$f0 > 0) & (params$f1 == 1) )] = "soft"
# params$sweepType[( (params$f0 == 0) & (params$f1 < 1) )] = "partial"
# params$sweepType[( (params$f0 > 0) & (params$f1 < 1) )] = "soft+partial"
# table(params$sweepType)

# does short tf, long ta look similar to long tf, short ta
ggplot(params, aes(x = log10(tf), y = log10(ta), color = hscan)) +
  geom_point() +
  theme_classic() +
  scale_colour_gradient(high = "#B200B2", low = "#FFFF66", name = "Messer's\nHscan") +
  theme(text = element_text(size = 20)) +
  labs(x = "log10(fixation time)", y = "log10(sweep age)")

ggsave(paste("/mnt/home/robe1195/Josephs_Lab_Projects/selection-demography-cnn/results/", today, "/tf_vs_ta_vs_hscan.png", sep = ""), height = 7, width = 8)

ggplot(params, aes(x = log10(tf), y = log10(ta), color = log10(pi))) +
  geom_point() +
  theme_classic()

ggplot(params, aes(x = tf, y = ta, color = num_haplos)) +
  geom_point() +
  theme_classic()

ggplot(params, aes(x = tf, y = ta, color = omega)) +
  geom_point() +
  theme_classic()

ggplot(params, aes(x = tf, y = ta, color = zns)) +
  geom_point() +
  theme_classic()

ggplot(params, aes(x = tf, y = ta, color = gkl_var)) +
  geom_point() +
  theme_classic()

ggplot(params, aes(x = tf, y = ta, color = h123)) +
  geom_point() +
  theme_classic()

ggplot(params, aes(x=log10(tf), y=log10(ta)) ) +
  geom_density_2d_filled() +
  theme_classic()

ggplot(params, aes(x=log10(tf), y=log10(ta)) ) +
  geom_bin_2d() +
  theme_classic()

# distribution of tf
ggplot(params, aes(x = log10(tf))) +
  geom_density() +
  theme_classic() +
  labs(x = "log10(Fixation time)")

ggsave(paste("/mnt/home/robe1195/Josephs_Lab_Projects/selection-demography-cnn/results/", today, "/tf_distribution_by_sweep_type_", today, ".png", sep = ""), height = 7, width = 7)

# distribution of sweep ages: time between fixation and observation
ggplot(params, aes(x = log10(ta))) +
  geom_density() +
  theme_classic() +
  labs(x = "log10(sweep age: fixation-observation)")

# distribution of sweep ages: time between observation and mutation introduction
ggplot(params, aes(x = log10(tau - kappa))) +
  geom_density() +
  theme_classic() +
  labs(x = "log10(sweep age: mutation-observation)")

# compare different methods of calculating tajimas d
ggplot(params, aes(x = tajd, y = tajd_incomplete)) +
  geom_point() +
  theme_classic() +
  geom_abline(slope = 1, intercept = 0) +
  labs(x = "Tajima's D without missing data", y = "Tajima's D with missing data")

# how does nucleotide diversity correlate with tf and ta
ggplot(params, aes(y = log10(pi), x = log10(tf/Q))) +
  geom_point() +
  geom_hline(yintercept = log10((7e-8)*4*12400*0.16)) +
  theme_classic() +
  labs(y = "log10(Nucleotide diversity)", x = "log10(fixation time + 1)")

ggplot(params, aes(x = log10(pi), y = log10(ta/Q + 1))) +
  geom_point() +
  geom_vline(xintercept = log10((7e-8)*4*12400*0.16)) +
  theme_classic() +
  labs(x = "log10(Nucleotide diversity)", y = "log10(sweep age + 1)")

# how does tajimas d correlate with tf
ggplot(params, aes(y = tajd, x = log10(tf/Q))) +
  geom_point() +
  theme_classic() +
  labs(y = "Tajima's D", x = "log10(fixation time + 1)")

ggplot(params, aes(y = num_haplos, x = log10(tf/Q))) +
  geom_point() +
  theme_classic() +
  labs(y = "Number of diplotypes", x = "log10(fixation time + 1)")

ggplot(params, aes(y = log10(zns), x = log10(tf/Q))) +
  geom_point() +
  theme_classic() +
  labs(y = "log10(Kelly's Zns)", x = "log10(fixation time + 1)")

ggplot(params, aes(y = log10(hscan), x = log10(tf/Q))) +
  geom_point() +
  theme_classic() +
  labs(y = "Messer's Hscan", x = "log10(fixation time + 1)")

# get random sample of simulation outputs
mypics_sub = sample(mypics[(picids %in% params$ID)], size = 1000, replace = F)

# get sim ids
picids_sub = as.integer(gsub(".png", "", gsub("/mnt/scratch/robe1195/Josephs_Lab_Projects/selection-demography-cnn/workflow/data/images/slim_", "", mypics_sub)))

# get variable that outputs should predict 
y = log10(params[(params$ID %in% picids_sub), "tf"])
summary(y)

# define function for reading pngs,
read_png = function(x){
  print(x)
  temp_pic = readPNG(x)[,,1]
  melt(temp_pic)$value
}

# load sim outputs
mypics = lapply(mypics, read_png)

# bind all sim outputs together
mypics = do.call("cbind", mypics)

# convert gray pixels to 0.5
mypics[((mypics > 0) & (mypics < 1))] = 0.5

# simulations should be rows
# do PCA
pca_results = as.data.frame(prcomp(t(mypics), center = T)$x)

# visually show how PCs correlate with dependent variable
ggplot(pca_results, aes(PC1, PC2, color = y)) +
  geom_point() +
  theme_classic() +
  labs(title = "PCA of 5000 images") + 
  scale_color_scico(palette = "lajolla", name = "log10(Scaled fixation time)") 

ggsave(paste("/mnt/home/robe1195/Josephs_Lab_Projects/selection-demography-cnn/results/", today, "/pca_", today, ".png", sep = ""), height = 7, width = 7)

# test if PC's correlate with selection coefficient
plot(pca_results$PC1, y)
cor.test(pca_results$PC1, y, method = "spearman")

plot(pca_results$PC2, y)
cor.test(pca_results$PC2, y, method = "spearman")

plot(pca_results$PC3, y)
cor.test(pca_results$PC3, y, method = "spearman")
```

# scale times to fixation 
```{r}
exponential_integral = function(x){
  exp(-x)/x
}

inbreeding_integral = function(t, s, h, Fis){
  (exp(2*s*(h+Fis-h*Fis)*t) - 1)/t
}

expected_tf = function(N, s, h, sigma, Q){
  # scale population size and selection
  N_scaled = round(N/Q)
  s_scaled = s*Q
  x_scaled = 1/(2*N_scaled)
  
  # euler's constant
  gamma = 0.5772
  
  # fixation index
  Fis = sigma/(2-sigma)
  
  # effective population size
  Ne = N_scaled/(1+Fis)
  
  # time to fixation
  c_num = (3*h - 1 + Fis*(2 - 3*h))*log(1 - (1 - Fis)*h) + (2 - 3*h + Fis*(3*h - 1))*log(h + Fis - h*Fis) + (1 + Fis)*(log(4*Ne*s_scaled) + gamma) 
  
  c_denom = s_scaled*(h + Fis - h*Fis)*(1 - (1 - Fis)*h)
  
  c_term = c_num/c_denom
  
  a = -1/(s_scaled*(h + Fis - h*Fis)*(1 - exp(-4*Ne*s_scaled*(h+Fis-h*Fis)*x_scaled)))
  
  b = gamma + log(4*Ne*s_scaled*(h + Fis - h*Fis)*x_scaled)
  
  d = integrate(exponential_integral, lower = 4*Ne*s_scaled*(h + Fis - h*Fis)*x_scaled, upper = Inf)$value  
  
  f_num = -exp(-4*Ne*s_scaled*(h+Fis-h*Fis)*x_scaled) 
  f_denom = s_scaled*(h + Fis - h*Fis)*(1 - exp(-4*Ne*s_scaled*(h+Fis-h*Fis)*x_scaled))
  
  f = f_num/f_denom
  
  g = integrate(inbreeding_integral, lower = 0, upper = 2*Ne*x_scaled, s = s_scaled, h = h, Fis = Fis)$value
  
  result = c_term - a*(b + d) + f*g
  
  return(result)
}

expected_tf_soft = function(N, s, h, sigma, Q){
  # scale population size and selection
  N = N/Q
  s = s*Q
  
  # euler's constant
  gamma = 0.5772
  
  # fixation index
  Fis = sigma/(2-sigma)
  
  # effective population size
  Ne = N/(1+Fis)
  
  # initial frequency
  x = 1/(2*N)
  
  # calculate expected fixation time
  a = (gamma + log(4*Ne*s*(1 - (1 - Fis)*h)*(1 - x)))/(s*(1 - (1 - Fis)*h))
  
  b = log(x)/(s*(h + F - h*Fis))
  
  d = ((1 - Fis)*(1 - 2*h))/(s*(h + Fis - h*Fis)*(1 - (1 - Fis)*h))
  
  f = log( (h + Fis - h*Fis + (1 - Fis)*(1 - 2*h)*x)/(1 - (1 - Fis)*h) )
  
  return(a - b + d*f)
}

params$scaled_expected_tfs = mapply(expected_tf, N = 198400, s = params$sweepS, h = params$h, sigma = params$sigma, Q = params$Q)

summary(params$scaled_expected_tfs)

params$unscaled_expected_tfs = mapply(expected_tf, N = 198400, s = params$sweepS, h = params$h, sigma = params$sigma, Q = 1)

summary(params$unscaled_expected_tfs)

params$scaling_factors = params$unscaled_expected_tfs/params$scaled_expected_tfs

summary(params$scaling_factors)

all(params$scaling_factors < params$Q)

summary( (params$Q - params$scaling_factors)/params$Q*100 )

params$scaled_tf = (params$tf/params$Q)*params$scaling_factors

summary( (params$tf - params$scaled_tf)/params$tf*100 )

ggplot(params, aes(x = scaled_tf, y = tf)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0) +
  theme_classic() +
  labs(x = "Properly scaled simulated tf", y = "Improperly scaled simulated tf (Q*tf)")

ggsave(paste("/mnt/home/robe1195/Josephs_Lab_Projects/selection-demography-cnn/results/", today, "/properly_vs_improperly_scaled_tf_", today, ".png", sep = ""), height = 7, width = 7)

ggplot(params, aes(x = scaled_tf, y = unscaled_expected_tfs)) +
  geom_point(aes(color = kappa)) +
  geom_abline(slope = 1, intercept = 0) +
  #geom_smooth(method = "loess") + 
  theme_classic() +
  labs(x = "Properly scaled simulated tf", y = "Expected tf in unscaled population")

ggsave(paste("/mnt/home/robe1195/Josephs_Lab_Projects/selection-demography-cnn/results/", today, "/scaled_tf_vs_unscaled_expected_tf_", today, ".png", sep = ""), height = 7, width = 7)


# ggplot(params, aes(x = scaled_expected_tfs , y = unscaled_expected_tfs)) +
#   geom_point() +
#   geom_smooth(method = "lm") +
#   theme_classic() +
#   labs(x = "Expected tf in scaled population", y = "Expected tf in unscaled population")
# 
# correct_mod = lm(unscaled_expected_tfs ~ Q + scaled_expected_tfs, params)
# correct_coeff = coefficients(correct_mod)
# 
# params$scaled_tf = correct_coeff[1] + params$scaled_expected_tfs*correct_coeff[2] + correct_mod$residuals
# 
# # get formula to correct bias in expected tf line
# correct_mod = lm(tf/Q ~ scaled_expected_tfs, params)
# correct_coeff = coefficients(correct_mod)
# 
# params$scaled_tf = correct_coeff[1] + params$scaled_expected_tfs*correct_coeff[2] + correct_mod$residuals
# 
# summary(params$scaled_tf)
# #params$scaling_factors = params$unscaled_expected_tfs/params$scaled_expected_tfs
# 
# #sum(params$scaling_factors < params$Q)
# 
# #params$scaled_tf = (params$tf/params$Q)*params$scaling_factors
# 
# #params$scaled_expected_tfs = expected_tf(params$N, params$sweepS, params$h, params$sigma, params$Q)
# 
# ggplot(params, aes(x = scaled_expected_tfs , y = tf/Q)) +
#   geom_point() +
#   geom_abline(slope = 1, intercept = 0) +
#   geom_smooth(method = "lm") +
#   theme_classic() +
#   labs(y = "Simulated, unscaled tf", x = "Expected tf")
# 
# ggplot(params, aes(x = scaled_expected_tfs , y = scaled_tf), color = Q) +
#   geom_point() +
#   geom_abline(slope = 1, intercept = 0) +
#   geom_smooth(method = "lm") +
#   theme_classic() +
#   labs(y = "Properly scaled tf", x = "Expected tf in unscaled population")
# 
# 
# ggplot(params, aes(y = tf, x = unscaled_expected_tfs)) +
#   geom_point() +
#   geom_abline(slope = 1, intercept = 0) +
#   geom_smooth(method = "lm") +
#   theme_classic() +
#   labs(y = "Q*tf", x = "Expected tf")
# 
# ggplot(params, aes(y = scaled_tf, x = unscaled_expected_tfs)) +
#   geom_point() +
#   geom_abline(slope = 1, intercept = 0) +
#   geom_smooth(method = "lm") +
#   theme_classic() +
#   labs(y = "Properly scaled tf", x = "Expected tf")
# 
# ggplot(params, aes(x = log10(scaled_tf))) +
#   geom_density() +
#   theme_classic() +
#   labs(x = "log10(scaled tf)")

```

# approximate bayesian computation

## cross-fold validation to choose a model
```{r}
# cross validation on simulated datasets to test accuracy of abc
# methods = 3
# tolerances = 3
# statistics = 3
# total iterations = 3*3*3 = 27
cv.res.rej.median <- cv4abc(data.frame(tf=params$tf), params[,c(28:31, 34:45)], nval=100, tols=c(0.01, 0.05, 0.1), method="rejection", statistic = "median")

cv.res.rej.mean <- cv4abc(data.frame(tf=params$tf), params[,c(28:31, 34:45)], nval=200, tols=c(0.01, 0.05, 0.1), method="rejection", statistic = "mean")

cv.res.rej.mode <- cv4abc(data.frame(tf=params$tf), params[,c(28:31, 34:45)], nval=100, tols=c(0.01, 0.05, 0.1), method="rejection", statistic = "mode")

cv.res.reg.median <- cv4abc(data.frame(tf=params$tf), params[,c(28:31, 34:45)], nval=100, tols=c(0.01, 0.05, 0.1), method="ridge", statistic = "median")

cv.res.reg.mean <- cv4abc(data.frame(tf=params$tf), params[,c(28:31, 34:45)], nval=100, tols=c(0.01, 0.05, 0.1), method="ridge", statistic = "mean")

cv.res.reg.mode <- cv4abc(data.frame(tf=params$tf), params[,c(28:31, 34:45)], nval=100, tols=c(0.01, 0.05, 0.1), method="ridge", statistic = "mode")

summary(cv.res.rej.median)
summary(cv.res.rej.mean)
summary(cv.res.rej.mode)

summary(cv.res.reg.median)
summary(cv.res.reg.mean)
summary(cv.res.reg.mode)

# function to plot abc results
plot_abc_results = function(predictions, truth, model_labels){
  # Calculate correlation between truth and results
  my_cor_coeff = cor.test(predictions, truth, method = "pearson")
  cor_est = signif(my_cor_coeff$estimate, digits = 3)
  cor_lwb = signif(my_cor_coeff$conf.int[1], digits = 3)
  cor_upb = signif(my_cor_coeff$conf.int[2], digits = 3)
  cor_pvalue = signif(my_cor_coeff$p.value, digits = 3)
  
  # plot data
  plotdata = data.frame(predictions = predictions, truth = truth)
  
  ggplot(aes(y = log10(predictions), x = log10(truth)), data = plotdata) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "#8C0172", linewidth = 2) +
  #geom_smooth(method = "lm", color = "#9B951B", linewidth = 2) +
  theme_classic() +
  theme(text = element_text(size = 20)) +
  labs(x = "log10(Actual tf)", 
       y = "log10(Predicted tf)",
       title = paste(model_labels, "\nr = ", cor_est, "\nCI = [",  cor_lwb, ", ", cor_upb, "]" , "\np = ", cor_pvalue, sep = ""))
}

# rejection method

## mean
rej_mean_tol001_fig = plot_abc_results(cv.res.rej.mean$estim$tol0.01, cv.res.rej.mean$true$tf, "Rej, Mean, Tol = 0.01")

ggsave(paste("/mnt/home/robe1195/Josephs_Lab_Projects/selection-demography-cnn/results/", today, "/abc_rejection_mean_tol001_", today, ".png", sep = ""), height = 7, width = 7)

rej_mean_tol005_fig = plot_abc_results(cv.res.rej.mean$estim$tol0.05, cv.res.rej.mean$true$tf, "Rej, Mean, Tol = 0.05")

rej_mean_tol010_fig = plot_abc_results(cv.res.rej.mean$estim$tol0.1, cv.res.rej.mean$true$tf, "Rej, Mean, Tol = 0.1")



ggarrange(rej_mean_tol001_fig, rej_mean_tol005_fig, rej_mean_tol010_fig, nrow = 1, ncol = 3)
ggsave(paste("/mnt/home/robe1195/Josephs_Lab_Projects/selection-demography-cnn/results/", today, "/abc_rejection_mean_", today, ".png", sep = ""), height = 3, width = 8)

## median
rej_med_tol001_fig = plot_abc_results(cv.res.rej.median$estim$tol0.01, cv.res.rej.median$true$tf, "Rej, Med, Tol = 0.01")

rej_med_tol005_fig = plot_abc_results(cv.res.rej.median$estim$tol0.05, cv.res.rej.median$true$tf, "Rej, Med, Tol = 0.05")

rej_med_tol010_fig = plot_abc_results(cv.res.rej.median$estim$tol0.1, cv.res.rej.median$true$tf, "Rej, Med, Tol = 0.1")

ggarrange(rej_med_tol001_fig, rej_med_tol005_fig, rej_med_tol010_fig, nrow = 1, ncol = 3)
ggsave(paste("/mnt/home/robe1195/Josephs_Lab_Projects/selection-demography-cnn/results/", today, "/abc_rejection_median_", today, ".png", sep = ""), height = 3, width = 8)

## mode
rej_mode_tol001_fig = plot_abc_results(cv.res.rej.mode$estim$tol0.01, cv.res.rej.mode$true$tf, "Rej, Mode, Tol = 0.01")

rej_mode_tol005_fig = plot_abc_results(cv.res.rej.mode$estim$tol0.05, cv.res.rej.mode$true$tf, "Rej, Mode, Tol = 0.05")

rej_mode_tol010_fig = plot_abc_results(cv.res.rej.mode$estim$tol0.1, cv.res.rej.mode$true$tf, "Rej, Mode, Tol = 0.1")

ggarrange(rej_mode_tol001_fig, rej_mode_tol005_fig, rej_mode_tol010_fig, nrow = 1, ncol = 3)
ggsave(paste("/mnt/home/robe1195/Josephs_Lab_Projects/selection-demography-cnn/results/", today, "/abc_rejection_mode_", today, ".png", sep = ""), height = 3, width = 8)

# regression method

## mean

## median

## mode

```

## apply best method to make predictions on real data

```{r}
# data(human)
# 
# stat.italy.sim <- subset(stat.3pops.sim, subset=models=="bott")

# target = 1 row dataframe of observed summary statistics
# param = 1 column dataframe of parameter values from simulated datasets
# sumstat = matrix of summary statistics from simulated datasets
# res = abc(target=stat.voight["italian",], param=data.frame(Na=par.italy.sim[, "Ne"]), sumstat=stat.italy.sim, tol=0.05, transf=c("log"), method="neuralnet")
# 
# summary(res)
# hist(res)

#
# obs_index = sample(1:nrow(params), size = 1)
# 
# observation = params[obs_index,]
# obs_stats = observation[,28:44]
# 
# simulations = params[-obs_index,]
# sim_stats = simulations[,28:44]
# 
# res = abc(target=obs_stats, param=data.frame(tf=simulations$tf), sumstat = sim_stats, tol=0.1, transf=c("log"), method="neuralnet")
# summary(res)
# hist(res)
# abline(v = observation$tf)

# check that observed statistics actually fall within range of summary statistics
ggplot(params, aes(x = log10(pi))) +
    geom_density() +
    geom_vline(xintercept = log10(targets$V2), color = "red", lwd = 1.5, lty = 2) +
    theme_classic() +
    theme(text=element_text(size=20)) +
    labs(x = "log10(Nucleotide diversity)")
  
ggplot(params, aes(x = tajd)) +
    geom_density() +
    geom_vline(xintercept = targets$V4, color = "red", lwd = 1.5, lty = 2) +
    theme_classic() +
    theme(text=element_text(size=20)) +
    labs(x = "Tajima's D")

ggplot(params, aes(x = num_haplos)) +
    geom_density() +
    geom_vline(xintercept = targets$V7, color = "red", lwd = 1.5, lty = 2) +
    theme_classic() +
    theme(text=element_text(size=20)) +
    labs(x = "Number of diplotypes")

ggplot(params, aes(x = h123)) +
    geom_density() +
    geom_vline(xintercept = targets$V11, color = "red", lwd = 1.5, lty = 2) +
    theme_classic() +
    theme(text=element_text(size=20)) +
    labs(x = "Hscan")

ggplot(params, aes(x = gkl_var)) +
    geom_density() +
    geom_vline(xintercept = targets$V13, color = "red", lwd = 1.5, lty = 2) +
    theme_classic() +
    theme(text=element_text(size=20)) +
    labs(x = "gkl variance")

ggplot(params, aes(x = gkl_skew)) +
    geom_density() +
    geom_vline(xintercept = targets$V14, color = "red", lwd = 1.5, lty = 2) +
    theme_classic() +
    theme(text=element_text(size=20)) +
    labs(x = "gkl skew")

ggplot(params, aes(x = hscan)) +
    geom_density() +
    geom_vline(xintercept = targets$V18, color = "red", lwd = 1.5, lty = 2) +
    theme_classic() +
    theme(text=element_text(size=20)) +
    labs(x = "Hscan")

# load in targets
target_files = list.files(path = "/mnt/scratch/robe1195/Josephs_Lab_Projects/selection-demography-cnn/workflow", pattern = ".*_sweep_stats.tsv", full.names = T)

targets = lapply(target_files, read.table, sep = "\t")

targets = do.call("rbind", targets)

# function to use abc to make predictions
# target = 1 row dataframe of observed summary statistics
# param = 1 column dataframe of parameter values from simulated datasets
# sumstat = matrix of summary statistics from simulated datasets
abc_pred_for_real_data = function(target, param, sumstat, tol, method){
  
  # check if any stats have missing, undefined, or infinite values for the target
  inf_check = as.vector(apply(target, MARGIN = 1, FUN = is.infinite))
  nan_check = as.vector(apply(target, MARGIN = 1, FUN = is.nan))
  na_check = as.vector(apply(target, MARGIN = 1, FUN = is.na))
  
  ss_to_keep = ( !(inf_check) & !(nan_check) & !(na_check) )
  
  target = target[,ss_to_keep]
  sumstat = sumstat[,ss_to_keep]
  
  # use abc to make prediction
  my_prediction = abc(target=target, param=param, sumstat=sumstat, tol=tol, method=method)
  
  # plot point estimate and credible interval on posterior distribution
  plotdata = as.data.frame(my_prediction$unadj.values)

  cred_int = round(quantile(my_prediction$unadj.values, c(0.055, 0.945)))
  
  point_est = round(summary(my_prediction)[[4]])

  final_plot = ggplot(plotdata, aes(x = V1)) +
    geom_density() +
    geom_vline(xintercept = cred_int[1], color = "red", lwd = 1.5, lty = 2) +
    geom_vline(xintercept = point_est, color = "black", lwd = 1.5, lty = 2) +
    geom_vline(xintercept = cred_int[2], color = "red", lwd = 1.5, lty = 2) +
    theme_classic() +
    theme(text=element_text(size=20)) +
    labs(x = "tf", title = paste("point estimate = ", point_est, "\n89 % Cred. Int. = [", cred_int[1], ", ", cred_int[2], "]", sep = ""))
  
  return(final_plot)
  
}

# apply abc to each observation
abc_pred_for_real_data(targets[1,], data.frame(tf = params[,"tf"]), params[,28:45], 0.01, "rejection")
abc_pred_for_real_data(targets[2,], data.frame(tf = params[,"tf"]), params[,28:45], 0.01, "rejection")
abc_pred_for_real_data(targets[3,], data.frame(tf = params[,"tf"]), params[,28:45], 0.01, "rejection")
abc_pred_for_real_data(targets[4,], data.frame(tf = params[,"tf"]), params[,28:45], 0.01, "rejection")
abc_pred_for_real_data(targets[5,], data.frame(tf = params[,"tf"]), params[,28:45], 0.01, "rejection")
```

# Machine learning

## compare predictions to actual values on testing dataset
```{r}
#pred_vs_act = read.table("../workflow/predicted_vs_actual.txt")
train_pred_vs_act = read.table("/mnt/scratch/robe1195/Josephs_Lab_Projects/selection-demography-cnn/workflow/train_predicted_vs_actual.txt")

val_pred_vs_act = read.table("/mnt/scratch/robe1195/Josephs_Lab_Projects/selection-demography-cnn/workflow/val_predicted_vs_actual.txt")

test_pred_vs_act = read.table("/mnt/scratch/robe1195/Josephs_Lab_Projects/selection-demography-cnn/workflow/test_predicted_vs_actual.txt")

# subset data to remove outliers
#pred_vs_act = pred_vs_act[(pred_vs_act$V1 <= 5000),]

# distribution of fixation times

## training set
train_pred_vs_act_melt = melt(as.data.table(train_pred_vs_act), id = c("V1", "V4"))
train_pred_vs_act_melt$variable = as.character(train_pred_vs_act_melt$variable)
train_pred_vs_act_melt$variable[(train_pred_vs_act_melt$variable == "V2")] = "Actual"
train_pred_vs_act_melt$variable[(train_pred_vs_act_melt$variable == "V3")] = "Predicted"

ggplot(train_pred_vs_act_melt, aes(x = value, color = variable)) +
  geom_density() +
  theme_classic() +
  labs(x = "log10(Fixation time)", color = "Type", title = "Training set")

ggsave(paste("/mnt/home/robe1195/Josephs_Lab_Projects/selection-demography-cnn/results/", today, "/train_actual-vs-predicted_density_", today, ".png", sep = ""), height = 7, width = 7)

## validation set
#val_pred_vs_act$V2 = log10(val_pred_vs_act$V2)
val_pred_vs_act_melt = melt(as.data.table(val_pred_vs_act), id = c("V1", "V4"))
val_pred_vs_act_melt$variable = as.character(val_pred_vs_act_melt$variable)
val_pred_vs_act_melt$variable[(val_pred_vs_act_melt$variable == "V2")] = "Actual"
val_pred_vs_act_melt$variable[(val_pred_vs_act_melt$variable == "V3")] = "Predicted"

ggplot(val_pred_vs_act_melt, aes(x = value, color = variable)) +
  geom_density() +
  theme_classic() +
  theme(text= element_text(size = 20)) +
  labs(x = "log10(Fixation time)", color = "Type", title = "Valdiation set")

ggsave(paste("/mnt/home/robe1195/Josephs_Lab_Projects/selection-demography-cnn/results/", today, "/val_actual-vs-predicted_density_", today, ".png", sep = ""), height = 7, width = 7)

## testing set
#test_pred_vs_act$V2 = log10(test_pred_vs_act$V2)
test_pred_vs_act_melt = melt(as.data.table(test_pred_vs_act), id = c("V1", "V4"))
test_pred_vs_act_melt$variable = as.character(test_pred_vs_act_melt$variable)
test_pred_vs_act_melt$variable[(test_pred_vs_act_melt$variable == "V2")] = "Actual"
test_pred_vs_act_melt$variable[(test_pred_vs_act_melt$variable == "V3")] = "Predicted"

ggplot(test_pred_vs_act_melt, aes(x = value, color = variable)) +
  geom_density() +
  theme_classic() +
  theme(text= element_text(size = 20)) +
  labs(x = "log10(Fixation time)", color = "Type", title = "Testing set")

ggsave(paste("/mnt/home/robe1195/Josephs_Lab_Projects/selection-demography-cnn/results/", today, "/test_actual-vs-predicted_density_", today, ".png", sep = ""), height = 7, width = 7)

# actual vs predicted values

##training set
my_cor_coeff = cor.test(train_pred_vs_act$V2, train_pred_vs_act$V3, method = "pearson")

cor_est = signif(my_cor_coeff$estimate, digits = 3)
cor_lwb = signif(my_cor_coeff$conf.int[1], digits = 3)
cor_upb = signif(my_cor_coeff$conf.int[2], digits = 3)
cor_pvalue = signif(my_cor_coeff$p.value, digits = 3)

ggplot(aes(y = V3, x = V2), data = train_pred_vs_act) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "#8C0172", linewidth = 2) +
  geom_vline(xintercept = mean(train_pred_vs_act$V2), linewidth = 1, linetype = "dotted", color = "red") + 
  geom_hline(yintercept = mean(train_pred_vs_act$V3), linewidth = 1, linetype = "dotted", color = "red") + 
  geom_smooth(method = "lm", color = "#9B951B", linewidth = 2) +
  #geom_smooth(method = "loess", color = "#B2F2FD", linewidth = 2) +
  theme_classic() +
  theme(text= element_text(size = 20)) +
  labs(x = "log10(Actual Fixation time)", 
       y = "log10(Predicted Fixation time)",
       title = paste("Training set: r = ", cor_est, "\n95 % CI = [",  cor_lwb, ", ", cor_upb, "]\np = ", cor_pvalue, sep = ""))

ggsave(paste("/mnt/home/robe1195/Josephs_Lab_Projects/selection-demography-cnn/results/", today, "/train_actual-vs-predicted_scatter_", today, ".png", sep = ""), height = 7, width = 7)

## validation set
my_cor_coeff = cor.test(val_pred_vs_act$V2, val_pred_vs_act$V3, method = "pearson")

cor_est = signif(my_cor_coeff$estimate, digits = 3)
cor_lwb = signif(my_cor_coeff$conf.int[1], digits = 3)
cor_upb = signif(my_cor_coeff$conf.int[2], digits = 3)
cor_pvalue = signif(my_cor_coeff$p.value, digits = 3)

ggplot(aes(y = V2, x = V3), data = val_pred_vs_act) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "#8C0172", linewidth =
                2) +
  geom_vline(xintercept = mean(val_pred_vs_act$V2), linewidth = 1, linetype = "dotted", color = "red") + 
  geom_hline(yintercept = mean(val_pred_vs_act$V3), linewidth = 1, linetype = "dotted", color = "red") + 
  geom_smooth(method = "lm", color = "#9B951B", linewidth = 2) +
  #geom_smooth(method = "loess", color = "#B2F2FD", linewidth = 2) +
  theme_classic() +
  theme(text= element_text(size = 20)) +
  labs(y = "log10(Actual Fixation time)", 
       x = "log10(Predicted Fixation time)",
       title = paste("Validation set: r = ", cor_est, "\n95 % CI = [",  cor_lwb, ", ", cor_upb, "]\np = ", cor_pvalue, sep = ""))

ggsave(paste("/mnt/home/robe1195/Josephs_Lab_Projects/selection-demography-cnn/results/", today, "/val_actual-vs-predicted_scatter_", today, ".png", sep = ""), height = 7, width = 7)

## test set
my_cor_coeff = cor.test(test_pred_vs_act$V2, test_pred_vs_act$V3, method = "pearson")

cor_est = signif(my_cor_coeff$estimate, digits = 3)
cor_lwb = signif(my_cor_coeff$conf.int[1], digits = 3)
cor_upb = signif(my_cor_coeff$conf.int[2], digits = 3)
cor_pvalue = signif(my_cor_coeff$p.value, digits = 3)

ggplot(aes(y = V3, x = V2), data = test_pred_vs_act) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "#8C0172", linewidth = 2) +
  #geom_vline(xintercept = mean(test_pred_vs_act$V3), linewidth = 1, linetype = "dotted", color = "red") +
  #geom_hline(yintercept = mean(test_pred_vs_act$V2), linewidth = 1, linetype = "dotted", color = "red") + 
  #geom_smooth(method = "lm", color = "#9B951B", linewidth = 2) +
  #geom_smooth(method = "loess", color = "#B2F2FD", linewidth = 2) +
  theme_classic() +
  theme(text= element_text(size = 20)) +
  labs(x = "log10(Actual Fixation time)", 
       y = "log10(Predicted Fixation time)",
       title = paste("Testing set: r = ", cor_est, "\n95 % CI = [",  cor_lwb, ", ", cor_upb, "]\np = ", cor_pvalue, sep = ""))

ggsave(paste("/mnt/home/robe1195/Josephs_Lab_Projects/selection-demography-cnn/results/", today, "/test_actual-vs-predicted_scatter_", today, ".png", sep = ""), height = 7, width = 7)

# standard deviation of predictions 

## test set
test_cor_std_vs_act = cor.test(test_pred_vs_act$V2, test_pred_vs_act$V4, method = "pearson")

cor_est = signif(test_cor_std_vs_act$estimate, digits = 3)
cor_lwb = signif(test_cor_std_vs_act$conf.int[1], digits = 3)
cor_upb = signif(test_cor_std_vs_act$conf.int[2], digits = 3)
cor_pvalue = signif(test_cor_std_vs_act$p.value, digits = 3)

ggplot(aes(x = V2, y = V4), data = test_pred_vs_act) +
  geom_point() +
  geom_vline(xintercept = mean(test_pred_vs_act$V2), linewidth = 1, linetype = "dotted", color = "red") + 
  geom_hline(yintercept = mean(test_pred_vs_act$V4), linewidth = 1, linetype = "dotted", color = "red") + 
  geom_smooth(method = "lm", color = "#9B951B", linewidth = 2) +
  #geom_smooth(method = "loess", color = "#B2F2FD", linewidth = 2) +
  theme_classic() +
  theme(text= element_text(size = 20)) +
  labs(x = "log10(Actual Fixation time)", 
       y = "SD in log10(Predicted Fixation time)",
       title = paste("Testing set: r = ", cor_est, "\n95 % CI = [",  cor_lwb, ", ", cor_upb, "]\np = ", cor_pvalue, sep = ""))

ggsave(paste("/mnt/home/robe1195/Josephs_Lab_Projects/selection-demography-cnn/results/", today, "/test_actual-vs-predicted-sd_scatter_", today, ".png", sep = ""), height = 7, width = 7)

## validation set
val_cor_std_vs_act = cor.test(val_pred_vs_act$V2, val_pred_vs_act$V4, method = "pearson")

cor_est = signif(val_cor_std_vs_act$estimate, digits = 3)
cor_lwb = signif(val_cor_std_vs_act$conf.int[1], digits = 3)
cor_upb = signif(val_cor_std_vs_act$conf.int[2], digits = 3)
cor_pvalue = signif(val_cor_std_vs_act$p.value, digits = 3)

ggplot(aes(x = V2, y = V4), data = val_pred_vs_act) +
  geom_point() +
  geom_vline(xintercept = mean(val_pred_vs_act$V2), linewidth = 1, linetype = "dotted", color = "red") + 
  geom_hline(yintercept = mean(val_pred_vs_act$V4), linewidth = 1, linetype = "dotted", color = "red") + 
  geom_smooth(method = "lm", color = "#9B951B", linewidth = 2) +
  #geom_smooth(method = "loess", color = "#B2F2FD", linewidth = 2) +
  theme_classic() +
  theme(text= element_text(size = 20)) +
  labs(x = "log10(Actual Fixation time)", 
       y = "SD in log10(Predicted Fixation time)",
       title = paste("Validation set: r = ", cor_est, "\n95 % CI = [",  cor_lwb, ", ", cor_upb, "]\np = ", cor_pvalue, sep = ""))

ggsave(paste("/mnt/home/robe1195/Josephs_Lab_Projects/selection-demography-cnn/results/", today, "/val_actual-vs-predicted-sd_scatter_", today, ".png", sep = ""), height = 7, width = 7)

# variation in predictions vs sweep age
# ggplot(aes(x = V2, y = V4), data = val_pred_vs_act) +
#   geom_point() +
#   geom_vline(xintercept = mean(val_pred_vs_act$V2), linewidth = 1, linetype = "dotted", color = "red") + 
#   geom_hline(yintercept = mean(val_pred_vs_act$V4), linewidth = 1, linetype = "dotted", color = "red") + 
#   geom_smooth(method = "lm", color = "#9B951B", linewidth = 2) +
#   #geom_smooth(method = "loess", color = "#B2F2FD", linewidth = 2) +
#   theme_classic() +
#   labs(x = "log10(Actual Fixation time)", 
#        y = "SD in log10(Predicted Fixation time)",
#        title = paste("Validation set: r = ", cor_est, ", 95 % CI = [",  cor_lwb, ", ", cor_upb, "] , p = ", cor_pvalue, sep = ""))

# actual vs coefficient of variation in predictions
ggplot(aes(x = V2, y = V4/V3), data = test_pred_vs_act) +
  geom_point() +
  geom_smooth(method = "lm", color = "#9B951B", linewidth = 2) +
  #geom_smooth(method = "loess", color = "#B2F2FD", linewidth = 2) +
  theme_classic() +
  labs(x = "log10(Actual Fixation time)", 
       y = "CV in log10(Predicted Fixation time)",
       )

# Measure error between actual and predicted
# How does error correlate with simulation parameters?
test_pred_vs_act$error = (test_pred_vs_act$V2 - test_pred_vs_act$V3)^2
names(test_pred_vs_act)[1] = "ID"
errors = merge(params, test_pred_vs_act, by = "ID")

errors$NQ = errors$N/errors$Q
errors$SQ = errors$sweepS*errors$Q
errors$MQ = errors$mu*errors$Q
errors$RQ = errors$R*errors$Q
errors$TQ = errors$tau*errors$Q

error_mod = lm(log10(error) ~ NQ + log10(SQ) + sigma + h + sigma*h + log10(MQ) + log10(RQ) + TQ + B + U, data = errors)
summary(error_mod)
plot(error_mod)

step(error_mod)

error_mod = lm(log10(error) ~ log10(SQ) + NQ + h, data = errors)
summary(error_mod)
```
# Adjust model predictions so that they have a 1:1 relationship with simulations
```{r}

mod_pred_vs_act = lm(V3 ~ V2, data = test_pred_vs_act)
coef_pred_vs_act = coefficients(mod_pred_vs_act)
res_pred_vs_act = residuals(mod_pred_vs_act)

#y_star = test_pred_vs_act$V3 + (1 - coef_pred_vs_act[2])*test_pred_vs_act$V2 - coef_pred_vs_act[1]
y_star = (test_pred_vs_act$V3 - coef_pred_vs_act[1])/coef_pred_vs_act[2]

plotdata = data.frame(
  y_star = y_star,
  x = test_pred_vs_act$V2
)

#
ggplot(aes(x = x, y = y_star), data = plotdata) +
  geom_point() +
  #geom_smooth(method = "lm", color = "#9B951B", linewidth = 2) +
  geom_abline(slope = 1, intercept = 0) +
  theme_classic() +
  labs(x = "log10(Actual Fixation time)", 
       y = "log10(Predicted Fixation time, adjusted)")

cor.test(plotdata$x, plotdata$y_star)

# plot histogram
plotdata_melt = melt(plotdata)
plotdata_melt$variable = as.character(plotdata_melt$variable)
test_pred_vs_act_melt$variable[(plotdata_melt$variable == "V2")] = "Actual"
test_pred_vs_act_melt$variable[(plotdata_melt$variable == "V3")] = "Predicted"

ggplot(test_pred_vs_act_melt, aes(x = value, color = variable)) +
  geom_density() +
  theme_classic() +
  labs(x = "log10(Fixation time)", color = "Type", title = "Testing set")
```


# How does time to fixation in simulations vary with the simulation parameters?
```{r}
#fix_times_files = list.files(path = "../workflow/data/fix_times", full.names = T)
# fix_times_files = list.files(path = "/mnt/scratch/robe1195/Josephs_Lab_Projects/selection-demography-cnn/workflow/data/fix_times", full.names = T)
# fix_times = lapply(fix_times_files, fread)

#fail_files = list.files(path = "../workflow/data/fails", full.names = T)
#fail_files = list.files(path = "/mnt/scratch/robe1195/Josephs_Lab_Projects/selection-demography-cnn/workflow/data/fails", full.names = T)
#fail_times = lapply(fail_files, fread)

# extract_number = function(x){
#   x$V1[1]
# }
# 
# fix_times = unlist(lapply(fix_times, extract_number))

#fail_times = unlist(lapply(fail_times, extract_number))

# fix_times = data.frame(
#   tf = fix_times,
#   ID = gsub(".txt", "", gsub(".*fix_time_", "",fix_times_files))
# )

#fail_times = data.frame(
#  fails = fail_times,
#  ID = gsub(".txt", "", gsub(".*fails_", "", fail_files))
#)

#fix_times = read.table("/mnt/scratch/robe1195/Josephs_Lab_Projects/selection-demography-cnn/workflow/fixation_times.txt", col.names = c("ID", "tf"))

#fix_times = merge(params, fix_times, by = "ID")
#fix_times = merge(fix_times, fail_times, by = "ID")

# convert tf to units of Ne
#fix_times$tfne = fix_times$tf/fix_times$Ne

# square selfing rate
#fix_times$sigma2 = fix_times$sigma^2

# remove any simulations that don't have images
image_ids = list.files(path = "/mnt/scratch/robe1195/Josephs_Lab_Projects/selection-demography-cnn/workflow/data/images", full.names = T)

image_ids = as.numeric(gsub(".*_", "", gsub(".png", "", image_ids)))

params = params[(params$ID %in% image_ids),]

# calculate probability of failure
# For each simulation, what geometric distribution would give the observed number of failures as it's expected value
#fix_times$fix_prob = 1/(fix_times$fails + 1)

# exploratory analysis, look at distribution of fix times
ggplot(fix_times, aes(x=tf)) +
  geom_density() +
  theme_classic() +
  labs(x = "fixation times")

ggplot(fix_times, aes(x=fails)) +
  geom_density() +
  theme_classic() +
  labs(x = "failures")

ggplot(fix_times, aes(x=log10(tf))) +
  geom_density() +
  theme_classic() +
  labs(x = "log10(fixation times)")

ggplot(fix_times, aes(x = log10(sweepS*Q), y = log10(tf))) +
  geom_point() +
  theme_classic()

ggplot(fix_times, aes(x=log10(fails + 1))) +
  geom_density() +
  theme_classic() +
  labs(x = "log10(failures + 1)")

ggplot(fix_times, aes(x=fix_prob)) +
  geom_density() +
  theme_classic() +
  labs(x = "Probability of fixation")

ggplot(fix_times, aes(x=log10(tf), y = log10(fails + 1))) +
  geom_point() +
  geom_smooth() +
  theme_classic() +
  labs(x = "Fixation time (generations)", y = "Failures")

cor.test(fix_times$tf, fix_times$fails, method = "spearman")

# change growth rate (r) to categorical variable
fix_times$rcat = NA
fix_times$rcat[(fix_times$r == 0)] = "constant"
fix_times$rcat[(fix_times$r > 0) & (fix_times$r < 0.5) & (fix_times$N < fix_times$K)] = "growing"
fix_times$rcat[(fix_times$r > 0) & (fix_times$r < 0.5) & (fix_times$N > fix_times$K)] = "shrinking"
fix_times$rcat[(fix_times$r > 2) & (fix_times$r < sqrt(6))] = "2-cycle"
fix_times$rcat[(fix_times$r > sqrt(6))] = "chaos"

table(fix_times$rcat)

fix_times$rcat = relevel(as.factor(fix_times$rcat), ref = "constant")

# calculate Ne
ggplot(fix_times[(fix_times$sweepS < 1/(fix_times$N*(2 - fix_times$sigma)/2)) & fix_times$rcat == "constant",], aes(x = N*(2-sigma)/2, y = tf)) +
  geom_point() +
  geom_abline(slope = 4, intercept = 0) +
  theme_classic()

# try linear models, see if there are any problems
tf_mod = lm(log10(tf) ~ log10(sweepS*Q) + h + log10(mu*Q) + log10(R*Q) + tau/Q + sigma + sigma*h + f0 + f1 + N/Q + n + lambda + n*lambda, data = fix_times)
summary(tf_mod)
plot(tf_mod)

fail_mod = lm(log10(fails + 1) ~ log10(sweepS) + h + log10(mu) + log10(R) + tau + sigma + sigma2 + sigma*h + f0 + f1 + N + n + rcat, data = fix_times)
summary(fail_mod)
plot(fail_mod)

# try glm instead of lm for fixation time
#tf_mod = glm(tf ~ log10(sweepS)+ h + log10(mu) + log10(R) + tau + f0 + f1 + N + lambda + n + r + sigma + sigma2 + sigma*h, data = fix_times, family = Gamma(link = "log"))
#summary(tf_mod)
#plot(tf_mod)

# fit model for failures
fail_mod = glm(fails ~ log10(sweepS)+ h + log10(mu) + log10(R) + tau + sigma + sigma2 + sigma*h + sigma*log10(R) + f0 + f1 + N + lambda + n + n*lambda + rcat, data = fix_times, family = "quasipoisson")
summary(fail_mod)
plot(fail_mod)

# find model with fewest terms but still lots of power
step(tf_mod, direction = "both")

# parametric plot of fixation time versus other parameters
ggplot(fix_times, aes(sigma, h, color = log(tf))) +
  geom_point() +
  theme_classic()

# re-fit model for only recessive mutations
tf_mod = lm(log10(tf) ~ log10(sweepS) + h + log10(mu) + log10(R) + sigma + sigma2 + sigma*h + sigma*log10(R) + N + n, data = fix_times[(fix_times$h < 0.5 & fix_times$f0 == 0 & fix_times$f1 == 1 & fix_times$rcat == "constant" & fix_times$M < 1),])
summary(tf_mod)

cor.test(fix_times$tf[(fix_times$h < 0.5)], fix_times$sigma[(fix_times$h < 0.5)])
```

# Stratified sampling along time to fixation
```{r}
# split
#widths_to_try = seq(from = 0.01, to = 1, by = 0.05)
#count_thresh = 1000

#for(width in widths_to_try){
#  breaks = seq(from = min(log10(fix_times$tf)), to = max(log10(fix_times$tf)), by = width)
#  fix_times$bin = cut(log10(fix_times$tf), breaks = breaks)
#  kept_bins = table(fix_times$bin)[table(fix_times$bin) > count_thresh]
#  total_in_downsample = min(kept_bins)*length(kept_bins)
#  print(paste("width: ", width, "; total: ", total_in_downsample))
#}

# focus on just hard sweeps
#fix_times = fix_times[(fix_times$f0 == 0 & fix_times$f1 == 1),]

width = 0.05
max_bin_height = 500

breaks = seq(from = min(log10(params$tf)) - width, to = max(log10(params$tf)) + width, by = width)
params$bin = cut(log10(params$tf), breaks = breaks)

table(params$bin)
max_bin_height = min(table(params$bin)[table(params$bin) >= max_bin_height])

strat_sample = NULL
for(bin in unique(params$bin)){
  fix_times_bin = params[(params$bin == bin),]
  if(nrow(fix_times_bin) >= max_bin_height){
    down_sampled_bin = fix_times_bin[sample(1:nrow(fix_times_bin), replace = F, size = max_bin_height),]
    strat_sample = rbind(strat_sample, down_sampled_bin)
  }
}

table(strat_sample$bin)
 
# check that tf is now uniformly distributed across data
ggplot(strat_sample, aes(x = log10(tf))) +
  geom_density() +
  theme_classic() +
  labs(x = "log10(Fixation time)")

ggplot(strat_sample, aes(x = log10(ta))) +
  geom_density() +
  theme_classic() +
  labs(x = "log10(sweep age)")

ggplot(strat_sample, aes(x=log10(tf), y=log10(ta)) ) +
  geom_bin_2d() +
  theme_classic()

ggplot(strat_sample, aes(x = log10(tf))) +
  geom_boxplot() +
  theme_classic() +
  labs(x = "log10(Fixation time)")

ggplot(strat_sample, aes(x = N)) +
  geom_density() +
  theme_classic() +
  labs(x = "Population size")

ggplot(strat_sample, aes(x = log10(mu))) +
  geom_density() +
  theme_classic() +
  labs(x = "log10(mutation rate)")

ggplot(strat_sample, aes(x = log10(R))) +
  geom_density() +
  theme_classic() +
  labs(x = "log10(recombination rate)")

ggplot(strat_sample, aes(x = tau)) +
  geom_density() +
  theme_classic() +
  labs(x = "Generations post-fixation when observed")

ggplot(strat_sample, aes(x = sigma)) +
  geom_density() +
  theme_classic() +
  labs(x = "Selfing rate")

ggplot(strat_sample, aes(x = h)) +
  geom_density() +
  theme_classic() +
  labs(x = "dominance coefficient")

ggplot(strat_sample, aes(x = log10(sweepS))) +
  geom_density() +
  theme_classic() +
  labs(x = "log10(selection coefficient)")

ggplot(fix_times, aes(x = log10(sweepS))) +
  geom_density() +
  theme_classic() +
  labs(x = "log10(selection coefficient)")

ggplot(strat_sample, aes(x = f0)) +
  geom_density() +
  theme_classic() +
  labs(x = "neutral -> benficial frequency")

ggplot(strat_sample, aes(x = f1)) +
  geom_density() +
  theme_classic() +
  labs(x = "beneficial -> neutral frequency")

ggplot(strat_sample, aes(x = B)) +
  geom_density() +
  theme_classic() +
  labs(x = "proportion of linked mutations which are beneficial")

ggplot(strat_sample, aes(x = U)) +
  geom_density() +
  theme_classic() +
  labs(x = "proportion of linked mutations which are deleterious")

ggplot(strat_sample, aes(x = M)) +
  geom_density() +
  theme_classic() +
  labs(x = "proportion of linked mutations which are neutral")

# Look at correlation between selection coefficient and tf
ggplot(strat_sample, aes(x = log10(sweepS*Q), y = log10(tf))) +
  geom_point() +
  theme_classic()

# randomly subsample data into training, testing, and validation
train_n = round(nrow(strat_sample)*0.8)
test_n = round(nrow(strat_sample)*0.1)
val_n = round(nrow(strat_sample)*0.1)

excess = (train_n + test_n + val_n) - nrow(strat_sample) # remove excess sims from partitioning
train_n = train_n - excess

train_n + test_n + val_n == nrow(strat_sample) # output should be TRUE

split_column = c(rep("train", times = train_n), rep("test", times = test_n), rep("val", times = val_n))

strat_sample$split = sample(split_column, replace = F, size = nrow(strat_sample))

table(strat_sample$split)

# What mean squared error would you expect if model predicted the mean for every image?
# This naive model would result in a loss equal to the variance of the response
var(log10(strat_sample[(strat_sample$split == "val"), "tf"]))

# check that dependent variable is still uniform after stratification
ggplot(strat_sample[(strat_sample$split == "train"),], aes(x=log10(tf))) +
  geom_density() +
  theme_classic() +
  labs(x = "log10(fixation times)")

ggplot(strat_sample[(strat_sample$split == "test"),], aes(x=log10(tf))) +
  geom_density() +
  theme_classic() +
  labs(x = "log10(fixation times)")

ggplot(strat_sample[(strat_sample$split == "val"),], aes(x=log10(tf))) +
  geom_density() +
  theme_classic() +
  labs(x = "log10(fixation times)")

# save stratified sample
write.table(strat_sample, "stratified_sample_16.tsv", sep = "\t", quote = F, row.names = F)
```

# subset simulations that are outside range of training data
```{r}
low_examples = params[(log10(params$tf) < min(train_pred_vs_act$V2)),]

high_examples = params[(log10(params$tf) > max(train_pred_vs_act$V2)),]

```

# evaluate results from real images
```{r}
real_pred = read.table("/mnt/scratch/robe1195/Josephs_Lab_Projects/selection-demography-cnn/workflow/real_predictions.txt", header = T)

ggplot(real_pred, aes(x=tf_mean)) +
  geom_density() +
  geom_vline(xintercept = 3.17) +
  theme_classic() +
  labs(x = "log10(predicted fixation times)")

# parse figure ids
split_ids = strsplit(real_pred$ID, "_")

extract_data = function(x, i){
  x[i]
}

real_pred$chrom = unlist(lapply(split_ids, FUN = extract_data, i = 1))
real_pred$start = unlist(lapply(split_ids, FUN = extract_data, i = 2))
real_pred$end = unlist(lapply(split_ids, FUN = extract_data, i = 3))

# plot 
ggplot(real_pred[(real_pred$chrom == "1"),], aes(x = start, y = tf_mean)) +
  geom_point() +
  theme_classic() +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  labs(x = "Position", y = "tf")

ggsave(paste("/mnt/home/robe1195/Josephs_Lab_Projects/selection-demography-cnn/results/", today, "/real_manhattan_chrom1_", today, ".png", sep = ""), height = 7, width = 7)
```

# Identify population-specific sweeps
```{r}
fst_files = list.files(path = "/mnt/ufs18/home-010/robe1195/Josephs_Lab_Projects/selection-demography-cnn/results/2024-08-21/", pattern = "_fst.txt", full.names = T)

fst_table = lapply(fst_files, FUN = read.table, sep = "\t", header = T)

fst_table = do.call("rbind", fst_table)

# max_fst_per_window = function(y, x){
#   
#   # subset dataframe to a particular window
#   x_sub = x[( (x$chromosome == y[1]) & (x$window_pos_1 == y[2]) ),]
#   
#   # exclude negative windows
#   x_sub = x_sub[(x_sub$avg_wc_fst > 0),]
#   
#   # get maximum fst in that window
#   result = x_sub[which.max(x_sub$avg_wc_fst),]
#   
#   # get result
#   return(result)
# }
# 
# min_fst_per_window = function(y, x){
#   
#   # subset dataframe to a particular window
#   x_sub = x[( (x$chromosome == y[1]) & (x$window_pos_1 == y[2]) ),]
#   
#   # exclude negative windows
#   x_sub = x_sub[(x_sub$avg_wc_fst > 0),]
#   
#   # get maximum fst in that window
#   result = x_sub[which.min(x_sub$avg_wc_fst),]
#   
#   # get result
#   return(result)
# }
# 
# max_fst_table = apply(unique(fst_table[,c("chromosome", "window_pos_1")]), FUN = max_fst_per_window, x = fst_table, MARGIN = 1)
# max_fst_table = do.call("rbind", max_fst_table)
# 
# min_fst_table = apply(unique(fst_table[,c("chromosome", "window_pos_1")]), FUN = min_fst_per_window, x = fst_table, MARGIN = 1)
# min_fst_table = do.call("rbind", min_fst_table)

# exclude windows with very few snps
# max_fst_table = max_fst_table[(max_fst_table$no_snps >= 30),]
# min_fst_table = min_fst_table[(min_fst_table$no_snps >= 30),]

# calculate branch length for PBS statistic
fst_table$branch_length = -log(1 - fst_table$avg_wc_fst)

# calculate PBS for south sweden, relative to south sweden and relicts
fst_south_north = fst_table[((fst_table$pop1 %in% c("north_sweden", "south_sweden")) & (fst_table$pop2 %in% c("north_sweden", "south_sweden"))),]
fst_south_relict = fst_table[((fst_table$pop1 %in% c("south_sweden", "relict")) & (fst_table$pop2 %in% c("south_sweden", "relict"))),]
fst_north_relict = fst_table[((fst_table$pop1 %in% c("relict", "north_sweden")) & (fst_table$pop2 %in% c("relict", "north_sweden"))),]

pbs_table = merge(fst_south_north, fst_south_relict, by = c("chromosome", "window_pos_1", "window_pos_2"))
pbs_table = merge(pbs_table, fst_north_relict, by = c("chromosome", "window_pos_1", "window_pos_2"))

# calculate branch lengths
pbs_table$branch_length = -log(pbs_table$avg_wc_fst)
pbs_table$branch_length.x = -log(pbs_table$avg_wc_fst.x)
pbs_table$branch_length.y = -log(pbs_table$avg_wc_fst.y)

# calculate pbs
pbs_table$pbs = (pbs_table$branch_length.x + pbs_table$branch_length.y - pbs_table$branch_length)/2

pbs_table = pbs_table[(pbs_table$no_snps >= 30),] # exclude windows with very few SNPs

pbs_table = pbs_table[!is.na(pbs_table$pbs),]

pbs_table = pbs_table[is.finite(pbs_table$pbs),]

# get top 1 %
top_cutoff = quantile(pbs_table$pbs, probs = 0.99)

# look at just north sweden vs south sweden
n_s_sweden_fst = fst_table[((fst_table$pop1 %in% c("north_sweden", "south_sweden")) & (fst_table$pop2 %in% c("north_sweden", "south_sweden"))),]

n_s_sweden_fst = n_s_sweden_fst[(n_s_sweden_fst$no_snps >= 30),]

# Plot Fst for north vs south sweden, see if known sweeps from other publications are there
ggplot(n_s_sweden_fst[(n_s_sweden_fst$chromosome == 1),], aes(x = (window_pos_1 + window_pos_2)/2, y = avg_wc_fst)) +
  geom_point() +
  geom_smooth(method = "loess", n = 1000, span = 0.1, color = "purple") +
  geom_hline(yintercept = mean(n_s_sweden_fst[(n_s_sweden_fst$chromosome == 1),"avg_wc_fst"]), linetype = 2) +
  geom_vline(xintercept = 20270000, color = "grey") + 
  geom_vline(xintercept = 19020000, color = "red") +
  theme_classic() +
  labs(x = "Middle of window", y = "Maximum Weir-Cockerham Fst\nacross all population pairs", title = "Chromosome 1")

ggplot(n_s_sweden_fst[(n_s_sweden_fst$chromosome == 4),], aes(x = (window_pos_1 + window_pos_2)/2, y = avg_wc_fst)) +
  geom_point() +
  geom_smooth(method = "loess", n = 1000, span = 0.1, color = "purple") +
  geom_hline(yintercept = mean(n_s_sweden_fst[(n_s_sweden_fst$chromosome == 4),"avg_wc_fst"]), linetype = 2) +
  geom_vline(xintercept = 6637000, color = "red") +
  theme_classic() +
  labs(x = "Middle of window", y = "Maximum Weir-Cockerham Fst\nacross all population pairs", title = "Chromosome 4")

ggplot(n_s_sweden_fst[(n_s_sweden_fst$chromosome == 5),], aes(x = (window_pos_1 + window_pos_2)/2, y = avg_wc_fst)) +
  geom_point() +
  geom_smooth(method = "loess", n = 1000, span = 0.1, color = "purple") +
  geom_hline(yintercept = mean(n_s_sweden_fst[(n_s_sweden_fst$chromosome == 5),"avg_wc_fst"]), linetype = 2) +
  geom_vline(xintercept = 2228000, color = "red") +
  geom_vline(xintercept = 6748000, color = "red") +
  geom_vline(xintercept = 26166000, color = "red") +
  theme_classic() +
  labs(x = "Middle of window", y = "Maximum Weir-Cockerham Fst\nacross all population pairs", title = "Chromosome 5")

# plot pbs for south sweden
ggplot(pbs_table[(pbs_table$chromosome == 1),], aes(x = (window_pos_1 + window_pos_2)/2, y = pbs)) +
  geom_point() +
  geom_smooth(method = "loess", n = 1000, span = 0.1, color = "purple") +
  geom_hline(yintercept = mean(pbs_table[(pbs_table$chromosome == 1),"pbs"], na.rm = T), linetype = 2) +
  geom_vline(xintercept = 20270000, color = "grey") + 
  geom_vline(xintercept = 19020000, color = "red") +
  geom_hline(yintercept = top_cutoff, lwd = 2) +
  theme_classic() +
  labs(x = "Middle of window", y = "Population branch statistic\nSouth Sweden focus", title = "Chromosome 1")

ggplot(pbs_table[(pbs_table$chromosome == 2),], aes(x = (window_pos_1 + window_pos_2)/2, y = pbs)) +
  geom_point() +
  geom_smooth(method = "loess", n = 1000, span = 0.1, color = "purple") +
  geom_hline(yintercept = mean(pbs_table[(pbs_table$chromosome == 1),"pbs"], na.rm = T), linetype = 2) +
  geom_hline(yintercept = top_cutoff, lwd = 2) +
  theme_classic() +
  labs(x = "Middle of window", y = "Population branch statistic\nSouth Sweden focus", title = "Chromosome 2")

ggplot(pbs_table[(pbs_table$chromosome == 3),], aes(x = (window_pos_1 + window_pos_2)/2, y = pbs)) +
  geom_point() +
  geom_smooth(method = "loess", n = 1000, span = 0.1, color = "purple") +
  geom_hline(yintercept = mean(pbs_table[(pbs_table$chromosome == 1),"pbs"], na.rm = T), linetype = 2) +
  geom_hline(yintercept = top_cutoff, lwd = 2) +
  theme_classic() +
  labs(x = "Middle of window", y = "Population branch statistic\nSouth Sweden focus", title = "Chromosome 3")

ggplot(pbs_table[(pbs_table$chromosome == 4),], aes(x = (window_pos_1 + window_pos_2)/2, y = pbs)) +
  geom_point() +
  geom_smooth(method = "loess", n = 1000, span = 0.1, color = "purple") +
  geom_hline(yintercept = mean(pbs_table[(pbs_table$chromosome == 1),"pbs"], na.rm = T), linetype = 2) +
  geom_hline(yintercept = top_cutoff, lwd = 2) +
  geom_vline(xintercept = 6637000, color = "red") +
  theme_classic() +
  labs(x = "Middle of window", y = "Population branch statistic\nSouth Sweden focus", title = "Chromosome 4")

ggplot(pbs_table[(pbs_table$chromosome == 5),], aes(x = (window_pos_1 + window_pos_2)/2, y = pbs)) +
  geom_point() +
  geom_smooth(method = "loess", n = 1000, span = 0.1, color = "purple") +
  geom_hline(yintercept = mean(pbs_table[(pbs_table$chromosome == 1),"pbs"], na.rm = T), linetype = 2) +
  geom_hline(yintercept = top_cutoff, lwd = 2) +
  geom_vline(xintercept = 2228000, color = "red") +
  geom_vline(xintercept = 6748000, color = "red") +
  geom_vline(xintercept = 26166000, color = "red") +
  theme_classic() +
  labs(x = "Middle of window", y = "Population branch statistic\nSouth Sweden focus", title = "Chromosome 5")
```

```{r}
# plot max fst values by chromosome
ggplot(max_fst_table[(max_fst_table$chromosome == 1),], aes(x = (window_pos_1 + window_pos_2)/2, y = avg_wc_fst)) +
  geom_point() +
  geom_smooth(method = "loess", n = 1000, span = 0.1, color = "purple") +
  geom_hline(yintercept = mean(max_fst_table[(max_fst_table$chromosome == 1),"avg_wc_fst"]), linetype = 2) +
  geom_vline(xintercept = 20270000, color = "red") + # known sweep
  geom_vline(xintercept = 15000000, color = "grey") + # centromere
  theme_classic() +
  labs(x = "Middle of window", y = "Maximum Weir-Cockerham Fst\nacross all population pairs", title = "Chromosome 1")

ggplot(max_fst_table[(max_fst_table$chromosome == 2),], aes(x = (window_pos_1 + window_pos_2)/2, y = avg_wc_fst)) +
  geom_point() +
  geom_smooth(method = "loess", n = 1000, span = 0.1, color = "purple") +
  geom_hline(yintercept = mean(max_fst_table[(max_fst_table$chromosome == 2),"avg_wc_fst"]), linetype = 2) +
  theme_classic() +
  labs(x = "Middle of window", y = "Maximum Weir-Cockerham Fst\nacross all population pairs", title = "Chromosome 2")

ggplot(max_fst_table[(max_fst_table$chromosome == 3),], aes(x = (window_pos_1 + window_pos_2)/2, y = avg_wc_fst)) +
  geom_point() +
  geom_smooth(method = "loess", n = 1000, span = 0.1, color = "purple") +
  geom_hline(yintercept = mean(max_fst_table[(max_fst_table$chromosome == 3),"avg_wc_fst"]), linetype = 2) +
  theme_classic() +
  labs(x = "Middle of window", y = "Maximum Weir-Cockerham Fst\nacross all population pairs", title = "Chromosome 3")

ggplot(max_fst_table[(max_fst_table$chromosome == 4),], aes(x = (window_pos_1 + window_pos_2)/2, y = avg_wc_fst)) +
  geom_point() +
  geom_smooth(method = "loess", n = 1000, span = 0.1, color = "purple") +
  geom_hline(yintercept = mean(max_fst_table[(max_fst_table$chromosome == 4),"avg_wc_fst"]), linetype = 2) +
  theme_classic() +
  labs(x = "Middle of window", y = "Maximum Weir-Cockerham Fst\nacross all population pairs", title = "Chromosome 4")

ggplot(max_fst_table[(max_fst_table$chromosome == 5),], aes(x = (window_pos_1 + window_pos_2)/2, y = avg_wc_fst)) +
  geom_point() +
  geom_smooth(method = "loess", n = 1000, span = 0.1, color = "purple") +
  geom_hline(yintercept = mean(max_fst_table[(max_fst_table$chromosome == 5),"avg_wc_fst"]), linetype = 2) +
  theme_classic() +
  labs(x = "Middle of window", y = "Maximum Weir-Cockerham Fst\nacross all population pairs", title = "Chromosome 5")

# plot min fst values by chromosome
ggplot(min_fst_table[(min_fst_table$chromosome == 1),], aes(x = (window_pos_1 + window_pos_2)/2, y = avg_wc_fst)) +
  geom_point() +
  geom_smooth(method = "loess", n = 1000, span = 0.1, color = "purple") +
  geom_hline(yintercept = mean(min_fst_table[(min_fst_table$chromosome == 1),"avg_wc_fst"]), linetype = 2) +
  geom_vline(xintercept = 23060322) +
  theme_classic() +
  labs(x = "Middle of window", y = "Minimum Weir-Cockerham Fst\nacross all population pairs", title = "Chromosome 1")

ggplot(min_fst_table[(min_fst_table$chromosome == 2),], aes(x = (window_pos_1 + window_pos_2)/2, y = avg_wc_fst)) +
  geom_point() +
  geom_smooth(method = "loess", n = 1000, span = 0.1, color = "purple") +
  geom_hline(yintercept = mean(min_fst_table[(min_fst_table$chromosome == 2),"avg_wc_fst"]), linetype = 2) +
  theme_classic() +
  labs(x = "Middle of window", y = "Minimum Weir-Cockerham Fst\nacross all population pairs", title = "Chromosome 2")

ggplot(min_fst_table[(min_fst_table$chromosome == 3),], aes(x = (window_pos_1 + window_pos_2)/2, y = avg_wc_fst)) +
  geom_point() +
  geom_smooth(method = "loess", n = 1000, span = 0.1, color = "purple") +
  geom_hline(yintercept = mean(min_fst_table[(min_fst_table$chromosome == 3),"avg_wc_fst"]), linetype = 2) +
  theme_classic() +
  labs(x = "Middle of window", y = "Minimum Weir-Cockerham Fst\nacross all population pairs", title = "Chromosome 3")

ggplot(min_fst_table[(min_fst_table$chromosome == 4),], aes(x = (window_pos_1 + window_pos_2)/2, y = avg_wc_fst)) +
  geom_point() +
  geom_smooth(method = "loess", n = 1000, span = 0.1, color = "purple") +
  geom_hline(yintercept = mean(min_fst_table[(min_fst_table$chromosome == 4),"avg_wc_fst"]), linetype = 2) +
  theme_classic() +
  labs(x = "Middle of window", y = "Minimum Weir-Cockerham Fst\nacross all population pairs", title = "Chromosome 4")

```

# DEPRECATED
```{r}
expected_seg_sites = function(N,mu,sigma,L){

4*mu*(N/(1 + sigma/(2-sigma)))*L

}

expected_seg_sites(1000,1e-8,0,1e6)
```

#
```{r}
s = runif(6000)
h = runif(6000)

fixtimes = data.frame(
  id = 1:6000,
  hs = h*s
)

fixtimes$bins = cut(fixtimes$hs, breaks = 10)

target = min(table(fixtimes$bins))

for(bin in unique(fixtimes$bins)){
    fixsub = fixtimes[(fixtimes$bins == bin),]
    fixsub[(fixsub$id %in% sample(fixsub$id, size = target, replace = F)),]
}

table(bins)


```

# shape data into one matrix
```{r}
# get max number of variants so, we know what to pad to
rowPadMax = max(unlist(lapply(vcfs, nrow)))

# zero pad or subsample data as necessary so all tables have same dimmensions
zeropad = function(x, rowPadMax){
  varCount = nrow(x)

  # subsample data if there are too many variants
  if(varCount > rowPadMax){
    x = x[sort(sample(1:varCount, rowPadMax, replace = F)),]
  }

  # Add zero-padds if there are too few variants
  if(varCount < rowPadMax){
    lastVar = x[varCount,"POS"]
    for(i in 1:(rowPadMax - varCount)){
      x = rbind(x, c(1, lastVar + i, "MT=0;", rep(0, times = 128)))
    }
  }
  
  return(x)
}

vcfs = lapply(vcfs, zeropad, rowPadMax = rowPadMax)

# melt vcfs
meltvcfs = function(x){
  x = melt(x, id.vars = c("CHROM", "POS", "INFO"))
  return(x[,5])
}

vcfs = lapply(vcfs, meltvcfs)

# combine all vcfs into one matrix
vcfs = do.call("cbind", vcfs)
dim(vcfs)

# convert all columns to numeric
vcfs = apply(vcfs, MARGIN = 2, as.numeric)
dim(vcfs)
```

# PCA and correlations
```{r}
# simulations should be rows
tvcfs = t(vcfs)

# tvcfsNoZero = tvcfs[,apply(tvcfs, 2, function(x){length(unique(x)) > 1})]

# do PCA
vcfpca = prcomp(tvcfs, center = T)

plot(vcfpca)
plot(vcfpca$x)

# If outcome is binary, look for association using logistic regression
regframe = as.data.frame(cbind(y, vcfpca$x))
regframe$y = as.factor(regframe$y)

mod = glm(y ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6, data = regframe, family = "binomial")
summary(mod)

# visually show how PCs correlate with dependent variable
ggplot(regframe, aes(PC1, PC2, color = y)) +
  geom_point() +
  theme_classic() +
  scale_color_scico_d(palette = "hawaii", labels = c("Neutral", "Selective sweep"), name = "Simulation")

ggsave("pca.png", scale = 0.5, width = 10, height = 7)

# correlate PCs with the dependent variable
plot(vcfpca$x[,1], y)
cor.test(vcfpca$x[,1], y, method = "spearman")

plot(vcfpca$x[,2], log(y))
cor.test(vcfpca$x[,2], log(y), method = "spearman")
```

