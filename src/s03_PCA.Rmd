---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---


# load packages
```{r}
rm(list = ls())
library(data.table)
library(reshape2)
library(ggplot2)
library(scico)
library(png)

today = Sys.Date()
```

# load data
```{r}
# simulation parameters
#params = read.table("../config/parameters.tsv", sep = "\t", header = T)
params = read.table("/mnt/scratch/robe1195/Josephs_Lab_Projects/selection-demography-cnn/config/parameters.tsv", sep = "\t", header = T)

# get random sample of simulation outputs
mypics = list.files("../workflow/data/images", full.names = T)

# get sim ids
picids = as.numeric(gsub(".png", "", gsub("../workflow/data/images/slim_", "", mypics)))

# get variable that outputs should predict 
y = params[picids, "sweepS"]
summary(y)

# define function for reading pngs,
read_png = function(x){
  print(x)
  temp_pic = readPNG(x)[,,1]
  melt(temp_pic)$value
}

# load sim outputs
mypics = lapply(mypics, read_png)

# bind all sim outputs together
mypics = do.call("cbind", mypics)

# convert gray pixels to 0.5
mypics[((mypics > 0) & (mypics < 1))] = 0.5

# simulations should be rows
# do PCA
pca_results = as.data.frame(prcomp(t(mypics), center = T)$x)

# visually show how PCs correlate with dependent variable
ggplot(pca_results, aes(PC1, PC2, color = y)) +
  geom_point() +
  theme_classic() +
  scale_color_scico(palette = "lajolla", name = "Selection coefficient")

# test if PC's correlate with selection coefficient
plot(pca_results$PC1, y)
cor.test(pca_results$PC1, y, method = "pearson")

plot(pca_results$PC2, y)
cor.test(pca_results$PC2, y, method = "pearson")

plot(pca_results$PC3, y)
cor.test(pca_results$PC3, y, method = "pearson")
```

# compare predictions to actual values on testing dataset
```{r}
#pred_vs_act = read.table("../workflow/predicted_vs_actual.txt")
pred_vs_act = read.table("/mnt/scratch/robe1195/Josephs_Lab_Projects/selection-demography-cnn/workflow/predicted_vs_actual.txt")

# subset data to remove outliers
#pred_vs_act = pred_vs_act[(pred_vs_act$V1 <= 5000),]
pred_vs_act_melt = melt(pred_vs_act)
pred_vs_act_melt$variable = as.character(pred_vs_act_melt$variable)
pred_vs_act_melt$variable[(pred_vs_act_melt$variable == "V1")] = "Actual"
pred_vs_act_melt$variable[(pred_vs_act_melt$variable == "V2")] = "Predicted"
# distribution of fixation times
ggplot(pred_vs_act_melt, aes(x = value, color = variable)) +
  geom_density() +
  theme_classic() +
  labs(x = "log10(Fixation time, generations)", color = "Type")

ggplot(pred_vs_act, aes(x=V2)) +
  geom_density() +
  geom_vline(aes(xintercept = median(V2)), linetype = "dashed", color = "blue") +
  theme_classic() +
  labs(x = "predicted fixation times", le)

# nicer plots
my_cor_coeff = cor.test(pred_vs_act$V1, pred_vs_act$V2, method = "spearman")

ggplot(aes(x = V1, y = V2), data = pred_vs_act) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "#8C0172", linewidth = 2) +
  geom_smooth(method = "lm", color = "#9B951B", linewidth = 2) +
  #geom_smooth(method = "loess", color = "#B2F2FD", linewidth = 2) +
  theme_classic() +
  labs(x = "log10(Actual fixation time, generations)", 
       y = "log10(Predicted fixation time, generations)",
       title = paste("\u03c1 = ", signif(my_cor_coeff$estimate, digits = 3), ", p = ", my_cor_coeff$p.value, sep = ""))

ggsave(paste("../results/actual_vs_predicted_fix_time_", today, ".png", sep = ""), height = 7, width = 7)

```

# How does time to fixation in simulations vary with the simulation parameters?
```{r}
#fix_times_files = list.files(path = "../workflow/data/fix_times", full.names = T)
fix_times_files = list.files(path = "/mnt/scratch/robe1195/Josephs_Lab_Projects/selection-demography-cnn/workflow/data/fix_times", full.names = T)
fix_times = lapply(fix_times_files, fread)

#fail_files = list.files(path = "../workflow/data/fails", full.names = T)
fail_files = list.files(path = "/mnt/scratch/robe1195/Josephs_Lab_Projects/selection-demography-cnn/workflow/data/fails", full.names = T)
fail_times = lapply(fail_files, fread)

extract_number = function(x){
  x$V1[1]
}

fix_times = unlist(lapply(fix_times, extract_number))

fail_times = unlist(lapply(fail_times, extract_number))

fix_times = data.frame(
  tf = fix_times,
  ID = gsub(".txt", "", gsub(".*fix_time_", "",fix_times_files))
)

fail_times = data.frame(
  fails = fail_times,
  ID = gsub(".txt", "", gsub(".*fails_", "", fail_files))
)

fix_times = merge(params, fix_times, by = "ID")
fix_times = merge(fix_times, fail_times, by = "ID")

# square selfing rate
fix_times$sigma2 = fix_times$sigma^2

# calculate probability of failure
# For each simulation, what geometric distribution would give the observed number of failures as it's expected value
fix_times$fix_prob = 1/(fix_times$fails + 1)

# exploratory analysis, look at distribution of fix times
ggplot(fix_times, aes(x=tf)) +
  geom_density() +
  theme_classic() +
  labs(x = "fixation times")

ggplot(fix_times, aes(x=fails)) +
  geom_density() +
  theme_classic() +
  labs(x = "failures")

ggplot(fix_times, aes(x=log10(tf))) +
  geom_density() +
  theme_classic() +
  labs(x = "log10(fixation times)")

ggplot(fix_times, aes(x=log10(fails + 1))) +
  geom_density() +
  theme_classic() +
  labs(x = "log10(failures + 1)")

ggplot(fix_times, aes(x=fix_prob)) +
  geom_density() +
  theme_classic() +
  labs(x = "Probability of fixation")

ggplot(fix_times, aes(x=log10(tf), y = log10(fails + 1))) +
  geom_point() +
  geom_smooth() +
  theme_classic() +
  labs(x = "Fixation time (generations)", y = "Failures")

cor.test(fix_times$tf, fix_times$fails, method = "spearman")

# change growth rate (r) to categorical variable
fix_times$rcat = NA
fix_times$rcat[(fix_times$r == 0)] = "constant"
fix_times$rcat[(fix_times$r > 0) & (fix_times$r < 0.5) & (fix_times$N < fix_times$K)] = "growing"
fix_times$rcat[(fix_times$r > 0) & (fix_times$r < 0.5) & (fix_times$N > fix_times$K)] = "shrinking"
fix_times$rcat[(fix_times$r > 2) & (fix_times$r < sqrt(6))] = "2-cycle"
fix_times$rcat[(fix_times$r > sqrt(6))] = "chaos"

table(fix_times$rcat)

fix_times$rcat = relevel(as.factor(fix_times$rcat), ref = "constant")

# try linear models, see if there are any problems
tf_mod = lm(log10(tf) ~ log10(sweepS) + h + log10(mu) + log10(R) + tau + sigma + sigma2 + sigma*h + sigma*log10(R) + f0 + f1 + N + n + lambda + n*lambda + rcat, data = fix_times)
summary(tf_mod)
plot(tf_mod)

fail_mod = lm(log10(fails + 1) ~ log10(sweepS) + h + log10(mu) + log10(R) + tau + sigma + sigma2 + sigma*h + f0 + f1 + N + n + rcat, data = fix_times)
summary(fail_mod)
plot(fail_mod)

# try glm instead of lm for fixation time
#tf_mod = glm(tf ~ log10(sweepS)+ h + log10(mu) + log10(R) + tau + f0 + f1 + N + lambda + n + r + sigma + sigma2 + sigma*h, data = fix_times, family = Gamma(link = "log"))
#summary(tf_mod)
#plot(tf_mod)

# fit model for failures
fail_mod = glm(fails ~ log10(sweepS)+ h + log10(mu) + log10(R) + tau + sigma + sigma2 + sigma*h + sigma*log10(R) + f0 + f1 + N + lambda + n + n*lambda + rcat, data = fix_times, family = "quasipoisson")
summary(fail_mod)
plot(fail_mod)

# find model with fewest terms but still lots of power
step(tf_mod, direction = "both")

# parametric plot of fixation time versus other parameters
ggplot(fix_times, aes(sigma, h, color = log(tf))) +
  geom_point() +
  theme_classic()

# re-fit model for only recessive mutations
tf_mod = lm(log10(tf) ~ log10(sweepS) + h + log10(mu) + log10(R) + sigma + sigma2 + sigma*h + sigma*log10(R) + N + n, data = fix_times[(fix_times$h < 0.5 & fix_times$f0 == 0 & fix_times$f1 == 1 & fix_times$rcat == "constant" & fix_times$M < 1),])
summary(tf_mod)

cor.test(fix_times$tf[(fix_times$h < 0.5)], fix_times$sigma[(fix_times$h < 0.5)])
```

#
```{r}
expected_seg_sites = function(N,mu,sigma,L){

4*mu*(N/(1 + sigma/(2-sigma)))*L

}

expected_seg_sites(1000,1e-8,0,1e6)
```

#
```{r}
s = runif(6000)
h = runif(6000)

fixtimes = data.frame(
  id = 1:6000,
  hs = h*s
)

fixtimes$bins = cut(fixtimes$hs, breaks = 10)

target = min(table(fixtimes$bins))

for(bin in unique(fixtimes$bins)){
    fixsub = fixtimes[(fixtimes$bins == bin),]
    fixsub[(fixsub$id %in% sample(fixsub$id, size = target, replace = F)),]
}

table(bins)


```

# shape data into one matrix
```{r}
# get max number of variants so, we know what to pad to
rowPadMax = max(unlist(lapply(vcfs, nrow)))

# zero pad or subsample data as necessary so all tables have same dimmensions
zeropad = function(x, rowPadMax){
  varCount = nrow(x)

  # subsample data if there are too many variants
  if(varCount > rowPadMax){
    x = x[sort(sample(1:varCount, rowPadMax, replace = F)),]
  }

  # Add zero-padds if there are too few variants
  if(varCount < rowPadMax){
    lastVar = x[varCount,"POS"]
    for(i in 1:(rowPadMax - varCount)){
      x = rbind(x, c(1, lastVar + i, "MT=0;", rep(0, times = 128)))
    }
  }
  
  return(x)
}

vcfs = lapply(vcfs, zeropad, rowPadMax = rowPadMax)

# melt vcfs
meltvcfs = function(x){
  x = melt(x, id.vars = c("CHROM", "POS", "INFO"))
  return(x[,5])
}

vcfs = lapply(vcfs, meltvcfs)

# combine all vcfs into one matrix
vcfs = do.call("cbind", vcfs)
dim(vcfs)

# convert all columns to numeric
vcfs = apply(vcfs, MARGIN = 2, as.numeric)
dim(vcfs)
```

# PCA and correlations
```{r}
# simulations should be rows
tvcfs = t(vcfs)

# tvcfsNoZero = tvcfs[,apply(tvcfs, 2, function(x){length(unique(x)) > 1})]

# do PCA
vcfpca = prcomp(tvcfs, center = T)

plot(vcfpca)
plot(vcfpca$x)

# If outcome is binary, look for association using logistic regression
regframe = as.data.frame(cbind(y, vcfpca$x))
regframe$y = as.factor(regframe$y)

mod = glm(y ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6, data = regframe, family = "binomial")
summary(mod)

# visually show how PCs correlate with dependent variable
ggplot(regframe, aes(PC1, PC2, color = y)) +
  geom_point() +
  theme_classic() +
  scale_color_scico_d(palette = "hawaii", labels = c("Neutral", "Selective sweep"), name = "Simulation")

ggsave("pca.png", scale = 0.5, width = 10, height = 7)

# correlate PCs with the dependent variable
plot(vcfpca$x[,1], y)
cor.test(vcfpca$x[,1], y, method = "spearman")

plot(vcfpca$x[,2], log(y))
cor.test(vcfpca$x[,2], log(y), method = "spearman")
```

